{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvlX7jOzPoq6"
      },
      "source": [
        "!wget -q -O corpora.zip https://www.dropbox.com/s/k23enjvr3fb40o5/corpora.zip?dl=0\n",
        "!unzip -q corpora.zip && rm corpora.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-2nnb-TQcgK"
      },
      "source": [
        "with open('/content/WarAndPeace.txt') as f:\n",
        "  corp_ru = f.read()\n",
        "with open('/content/WarAndPeaceEng.txt') as f:\n",
        "  corp_en = f.read()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvWWpcrtTD_N"
      },
      "source": [
        "# Реализуйте базовый частотный метод по Шерлоку Холмсу:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkWxhmOCTIa9"
      },
      "source": [
        "### Подсчитайте частоты букв по корпусам (пунктуацию и капитализацию можно просто опустить, а вот пробелы лучше оставить)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k55et_7lQ8sz"
      },
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "def sanitize(text, lang = 'ru'):\n",
        "  if lang == 'ru':\n",
        "    regexp = '[^а-я ]+'\n",
        "  else:\n",
        "    regexp = '[^a-z ]+'\n",
        "  return re.sub(regexp, '', text.lower())\n",
        "\n",
        "corp_ru = sanitize(corp_ru, lang = 'ru')\n",
        "corp_en = sanitize(corp_en, lang = 'en')\n",
        "\n",
        "ru_counts = Counter(corp_ru)\n",
        "en_counts = Counter(corp_en)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8u0VTTUMsVW9"
      },
      "source": [
        "RU_LETTERS = sorted([x for x in ru_counts.keys()])\n",
        "EN_LETTERS = sorted([x for x in en_counts.keys()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRkgUDccTVPl"
      },
      "source": [
        "### Возьмите какие-нибудь тестовые тексты (нужно взять по меньшей мере 2-3 предложения, иначе вряд ли сработает), зашифруйте их посредством случайной перестановки символов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcGltLNntaLY"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def encrypt(sentence, letters = RU_LETTERS):\n",
        "  key = {x: y for x,y in zip(letters, np.random.permutation(letters))}\n",
        "  encrypted = ''.join(map(key.get, sentence))\n",
        "  reverse_key = {x:y for y, x in key.items()}\n",
        "  return encrypted, reverse_key"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bn8gPm9nShrf"
      },
      "source": [
        "sample_text = \"\"\"Продвинутое машинное обучение: \n",
        "Домашнее задание 3\n",
        "Третье домашнее задание посвящено достаточно простой, но, надеюсь, интересной задаче, в которой потребуется творчески применить методы сэмплирования. Как и раньше, в качестве решения ожидается ссылка на jupyter-ноутбук на вашем github (или публичный, или с доступом для snikolenko); ссылку обязательно нужно прислать в виде сданного домашнего задания на портале Академии. Как всегда, любые комментарии, новые идеи и рассуждения на тему категорически приветствуются. \n",
        "В этом небольшом домашнем задании мы попробуем улучшить метод Шерлока Холмса. Как известно, в рассказе The Adventure of the Dancing Men великий сыщик расшифровал загадочные письмена, которые выглядели примерно так:\n",
        "\n",
        "Пользовался он для этого так называемым частотным методом: смотрел, какие буквы чаще встречаются в зашифрованных текстах, и пытался подставить буквы в соответствии с частотной таблицей: E — самая частая и так далее.\n",
        "В этом задании мы будем разрабатывать более современный и продвинутый вариант такого частотного метода. В качестве корпусов текстов для подсчётов частот можете взять что угодно, но для удобства вот вам “Война и мир” по-русски и по-английски:\n",
        "https://www.dropbox.com/s/k23enjvr3fb40o5/corpora.zip \n",
        "Реализуйте базовый частотный метод по Шерлоку Холмсу:\n",
        "подсчитайте частоты букв по корпусам (пунктуацию и капитализацию можно просто опустить, а вот пробелы лучше оставить);\n",
        "возьмите какие-нибудь тестовые тексты (нужно взять по меньшей мере 2-3 предложения, иначе вряд ли сработает), зашифруйте их посредством случайной перестановки символов;\n",
        "расшифруйте их таким частотным методом.\n",
        "Вряд ли в результате получилась такая уж хорошая расшифровка, разве что если вы брали в качестве тестовых данных целые рассказы. Но и Шерлок Холмс был не так уж прост: после буквы E, которая действительно выделяется частотой, дальше он анализировал уже конкретные слова и пытался угадать, какими они могли бы быть. Я не знаю, как запрограммировать такой интуитивный анализ, так что давайте просто сделаем следующий логический шаг:\n",
        "подсчитайте частоты биграмм (т.е. пар последовательных букв) по корпусам;\n",
        "проведите тестирование аналогично п.1, но при помощи биграмм.\n",
        "Но и это ещё не всё: биграммы скорее всего тоже далеко не всегда работают. Основная часть задания — в том, как можно их улучшить:\n",
        "предложите метод обучения перестановки символов в этом задании, основанный на MCMC-сэмплировании, но по-прежнему работающий на основе статистики биграмм;\n",
        "реализуйте и протестируйте его, убедитесь, что результаты улучшились.\n",
        "Расшифруйте сообщение:\n",
        "←⇠⇒↟↹↷⇊↹↷↟↤↟↨←↹↝⇛⇯↳⇴⇒⇈↝⇊↾↹↟⇒↟↹⇷⇛⇞↨↟↹↝⇛⇯↳⇴⇒⇈↝⇊↾↹↨←⇌⇠↨↹⇙↹⇸↨⇛↙⇛↹⇠⇛⇛↲⇆←↝↟↞↹⇌⇛↨⇛⇯⇊↾↹⇒←↙⇌⇛↹⇷⇯⇛⇞↟↨⇴↨⇈↹⇠⇌⇛⇯←←↹↷⇠←↙⇛↹↷⇊↹↷⇠←↹⇠↤←⇒⇴⇒↟↹⇷⇯⇴↷↟⇒⇈↝⇛↹↟↹⇷⇛⇒⇙⇞↟↨←↹↳⇴⇌⇠↟↳⇴⇒⇈↝⇊↾↹↲⇴⇒⇒↹⇰⇴↹⇷⇛⇠⇒←↤↝←←↹⇞←↨↷←⇯↨⇛←↹⇰⇴↤⇴↝↟←↹⇌⇙⇯⇠⇴↹↘⇛↨↞↹⇌⇛↝←⇞↝⇛↹↞↹↝↟⇞←↙⇛↹↝←↹⇛↲←⇆⇴⇏\n",
        "Или это (они одинаковые, второй вариант просто на случай проблем с юникодом):\n",
        "დჳჵჂႨშႼႨშჂხჂჲდႨსႹႭჾႣჵისႼჰႨჂჵჂႨႲႹႧჲჂႨსႹႭჾႣჵისႼჰႨჲდႩჳჲႨჇႨႠჲႹქႹႨჳႹႹჱჶდსჂႽႨႩႹჲႹႭႼჰႨჵდქႩႹႨႲႭႹႧჂჲႣჲიႨჳႩႹႭდდႨშჳდქႹႨშႼႨშჳდႨჳხდჵႣჵჂႨႲႭႣშჂჵისႹႨჂႨႲႹჵჇႧჂჲდႨჾႣႩჳჂჾႣჵისႼჰႨჱႣჵჵႨეႣႨႲႹჳჵდხსდდႨႧდჲშდႭჲႹდႨეႣხႣსჂდႨႩჇႭჳႣႨႾႹჲႽႨႩႹსდႧსႹႨႽႨსჂႧდქႹႨსდႨႹჱდჶႣნ\n",
        "Бонус: а что если от биграмм перейти к триграммам (тройкам букв) или даже больше? Улучшатся ли результаты? Когда улучшатся, а когда нет? Чтобы ответить на этот вопрос эмпирически, уже может понадобиться погенерировать много тестовых перестановок и последить за метриками, глазами может быть и не видно.\n",
        "Бонус: какие вы можете придумать применения для этой модели? Пляшущие человечки ведь не так часто встречаются в жизни (хотя встречаются! и это самое потрясающее во всей этой истории, но об этом я расскажу потом).\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XX4CLGtaTswG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "954ea435-2dd3-42c8-fb9f-06c1eb0803bc"
      },
      "source": [
        "sample_text = sanitize(sample_text)\n",
        "encrypted_text, key = encrypt(sample_text)\n",
        "encrypted_text[:500]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'пврчюстжерьшыл сттрьшргжаьтсьшчрыл тььшмлчлтсьшевьеиьшчрыл тььшмлчлтсьшпрдюфйьтршчрделератршпврдерзштрштлчькдишстеьвьдтрзшмлчлаьшюшэрерврзшпревьгжьедфшеюрваьдэсшпвсыьтсеишыьерчщшдхыпосврюлтсфшэлэшсшвлти ьшюшэлаьдеюьшвь ьтсфшрусчльедфшддщоэлштлштржегжэштлшюл ьышшсосшпжгосатщзшсосшдшчрдежпрышчофшшддщоэжшргфмлеьоитрштжутршпвсдолеишюшюсчьшдчлттрнршчрыл тьнршмлчлтсфштлшпрвелоьшлэлчьыссшэлэшюдьнчлшокгщьшэрыыьтелвссштрющьшсчьсшсшвлдджучьтсфштлшеьыжшэлеьнрвсаьдэсшпвсюьедеюжкедфшюшхерыштьгрои рышчрыл тьы'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Re_9eCFqdRYG"
      },
      "source": [
        "### Расшифруйте их таким частотным методом."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "yui47eq6W88X",
        "outputId": "245ffa2e-ed34-4c6e-f2ef-57e4d8de7727"
      },
      "source": [
        "def unigram_decryption_score(text, key, verbose = False):\n",
        "  text_counts = Counter(text)\n",
        "  correct = 0\n",
        "  replacer = dict()\n",
        "  for true, pred in zip(ru_counts.most_common(), text_counts.most_common()):\n",
        "    if true[0] == key[pred[0]]:\n",
        "      correct += pred[1]\n",
        "    replacer[pred[0]] = true[0]\n",
        "  if verbose:\n",
        "    print(f'Correctly decrypted {round(correct/len(text)*100,2)}% of text.\\n')\n",
        "  text = ''.join(map(replacer.get, text))\n",
        "  return text\n",
        "decrypted_text = unigram_decryption_score(encrypted_text, key, True)\n",
        "decrypted_text[:500]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Correctly decrypted 39.08% of text.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'пломвнсуеои ражнссои оьугисни моражсии чамасни елиези моражсии чамасни потвыэисо мотеаеогсо плотеоб со самихтз нсеилитсоб чамаги в доеолоб поелиьуиеты еволгитдн плнриснез риеомя тюрпкнловасны дад н ласзжи в дагитеви лижисны ошнмаиеты ттякда са соуеьуд са важир  нкн пуькнгсяб нкн т мотеупор мкы  ттякду оьычаеикзсо сушсо плнткаез в внми тмассойо моражсийо чамасны са полеаки адамирнн дад втийма кхьяи доррисеалнн совяи нмин н латтушмисны са еиру даеийолнгитдн плнвиетевухеты в юеор сиьокзжор моражсир'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVYtkN0be7xD"
      },
      "source": [
        "# Подсчитайте частоты биграмм (т.е. пар последовательных букв) по корпусам"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18jZA0IJdj33"
      },
      "source": [
        "def count_bigrams(corp):\n",
        "  bigrams = Counter()\n",
        "  for i in range(len(corp)-1):\n",
        "    bigrams.update([corp[i:i+2]])\n",
        "  return bigrams\n",
        "bigrams_ru = count_bigrams(corp_ru)\n",
        "bigrams_en = count_bigrams(corp_en)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xaf4B3wSRmA8"
      },
      "source": [
        "### Проведите тестирование аналогично п.1, но при помощи биграмм"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "ur4zGsBQ6VR4",
        "outputId": "afe744f3-179b-4b9f-fe84-a0fa101a7807"
      },
      "source": [
        "def bigram_decryption_score(text, key):\n",
        "  letter_counts = Counter(text)\n",
        "  text_counts = count_bigrams(text)\n",
        "  correct = 0\n",
        "  replacer = dict()\n",
        "  for true, pred in zip(bigrams_ru.most_common(), text_counts.most_common()):\n",
        "    for letter_true, letter_pred in zip(true[0], pred[0]):\n",
        "      if letter_pred not in replacer.keys() and letter_true not in replacer.values():\n",
        "        replacer[letter_pred] = letter_true\n",
        "  for k, v in zip(set(RU_LETTERS) - set(replacer.keys()), set(RU_LETTERS) - set(replacer.values())):\n",
        "    replacer[k] = v\n",
        "  for k, v in replacer.items():\n",
        "    if key[k] == v:\n",
        "      correct += letter_counts[k]\n",
        "  print(f'Correctly decrypted {round(correct/len(text)*100,2)}% of text.\\n')\n",
        "  text = ''.join(map(replacer.get, text))\n",
        "  return text\n",
        "\n",
        "decrypted_text = bigram_decryption_score(encrypted_text, key)\n",
        "decrypted_text[:500]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Correctly decrypted 28.74% of text.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'слндвикжано хйяиккно нзжцокио днхйякоо фйдйкио алоаео днхйякоо фйдйкио снчвщуокн днчайанцкн слнчаню кн кйдоьче икаолочкню фйдйцо в тнанлню сналозжоачщ авнлцочти слихокиае хоанды чмхсрилнвйкищ тйт и лйкеяо в тйцочаво лояокищ нгидйоачщ ччыртй кй кнжазжт кй вйяох  ири сжзрицкыю ири ч днчажснх дрщ  ччыртж нзщфйаорекн кжгкн сличрйае в видо чдйккншн днхйякошн фйдйкищ кй снлайро йтйдохии тйт вчошдй рьзыо тнххокайлии кнвыо идои и лйччжгдокищ кй аохж тйаошнлицочти сливоачавжьачщ в манх кознреянх днхйякох'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8tVwNuLR2gH"
      },
      "source": [
        "# Предложите метод обучения перестановки символов в этом задании, основанный на MCMC-сэмплировании, но по-прежнему работающий на основе статистики биграмм"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPxRBONj1wco"
      },
      "source": [
        "Сначала происходит перевод символов закодированного текста в символы тренировочного корпуса, затем производятся итерации алгоритма, меняющего местоположение 2 случайных букв между собой во всем тексте. На основании метрики правдоподобия нграмм в закодированном тексте принимается решение о сохранении получившегося текста либо откату назад с вероятностью пропорциональной величине различия метрики между получившимися текстами. (Metropolis–Hastings algorithm)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3F4xZf_eOu7x"
      },
      "source": [
        "class Decryptor():\n",
        "  def __init__(self, corpus, encrypted, iterations = 25000):\n",
        "    self.corpus = corpus\n",
        "    self.corpus_letters = sorted(set(corpus))\n",
        "    self.corpus_counts = dict()\n",
        "    self.encrypted_counts = dict()\n",
        "    self.encrypted = self.preprocess(encrypted)\n",
        "    self.letters_encrypted = set(self.encrypted)\n",
        "    self.iterations = iterations\n",
        "\n",
        "  def get_loss(self, bigrams, counts):\n",
        "    loss = 0\n",
        "    for i in bigrams.items():\n",
        "      if counts[i[0]] == 0:\n",
        "        loss += 2*i[1]\n",
        "      else:\n",
        "        loss += np.log(counts[i[0]])*i[1]\n",
        "    return -loss\n",
        "\n",
        "  def get_ngrams_corpus(self, n):\n",
        "    if n not in self.corpus_counts.keys():\n",
        "      self.corpus_counts[n] = self.count_ngrams(self.corpus, n)\n",
        "    return self.corpus_counts[n]\n",
        "  \n",
        "  def get_ngrams_encrypted(self, n):\n",
        "    if n not in self.encrypted_counts.keys():\n",
        "      self.encrypted_counts[n] = self.count_ngrams(self.encrypted, n)\n",
        "    return self.encrypted_counts[n]\n",
        "  \n",
        "  def count_ngrams(self, text, n):\n",
        "    ngrams = Counter()\n",
        "    for i in range(len(text)-n+1):\n",
        "      ngrams.update([text[i:i+n]])\n",
        "    return ngrams\n",
        "  \n",
        "  def preprocess(self, encrypted):\n",
        "    letters_text = set(encrypted)\n",
        "    to_lang = {letter: self.corpus_letters[i] for i, letter in enumerate(letters_text)}\n",
        "    encrypted = unigram_decryption_score(encrypted, to_lang)\n",
        "    return encrypted\n",
        "\n",
        "  def update(self, loss, temp_loss, text, temp_text, letters_text):\n",
        "    ratio = np.exp(max(-1000, min(1, loss - temp_loss)))\n",
        "\n",
        "    if temp_loss <= loss or ratio > np.random.uniform():\n",
        "      loss = temp_loss\n",
        "      text = temp_text\n",
        "      letters_text = set(text)\n",
        "    \n",
        "    return loss, text, letters_text\n",
        "\n",
        "  def ngram_mcmc(self, n):\n",
        "    ngrams_corpus = self.get_ngrams_corpus(n)\n",
        "    ngrams_encrypted = self.get_ngrams_encrypted(n)\n",
        "    letters_encrypted = self.letters_encrypted\n",
        "    text = self.encrypted\n",
        "    loss = float('+inf')\n",
        "\n",
        "    for _ in range(self.iterations):\n",
        "      first = np.random.choice(list(letters_encrypted), 1)[0]\n",
        "      second = np.random.choice(self.corpus_letters, 1)[0]\n",
        "      replacer = {x: x for x in letters_encrypted}\n",
        "      replacer[first], replacer[second] = second, first\n",
        "      temp_text = ''.join(map(replacer.get, text))\n",
        "\n",
        "      ngrams_encrypted = self.count_ngrams(temp_text, n)\n",
        "      temp_loss = self.get_loss(ngrams_encrypted, ngrams_corpus)\n",
        "\n",
        "      loss, text, letters_encrypted = self.update(loss, temp_loss, text, temp_text, letters_encrypted)\n",
        "\n",
        "    return loss, text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60176gcld7PH"
      },
      "source": [
        "### Реализуйте и протестируйте его, убедитесь, что результаты улучшились"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmLWzrBTgApV",
        "outputId": "73850b69-9c27-41c9-9624-803dc1b80ab8"
      },
      "source": [
        "def get_pred_score(true_text, decrypted_text):\n",
        "  i = 0\n",
        "  for true, pred in zip(true_text, decrypted_text):\n",
        "    if true == pred:\n",
        "      i+=1\n",
        "  return round(i/len(true_text)*100,2)\n",
        "\n",
        "decryptor = Decryptor(corp_ru, encrypted_text, iterations=25000)\n",
        "\n",
        "loss, decrypted_text = decryptor.ngram_mcmc(2)\n",
        "print(f'Loss: {loss}', f'Encrypted text:\\n{encrypted_text}', f'Decrypted text:\\n{decrypted_text}', f'Accuracy: {get_pred_score(sample_text, decrypted_text)}', sep = '\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: -22572.291939801784\n",
            "Encrypted text:\n",
            "пврчюстжерьшыл сттрьшргжаьтсьшчрыл тььшмлчлтсьшевьеиьшчрыл тььшмлчлтсьшпрдюфйьтршчрделератршпврдерзштрштлчькдишстеьвьдтрзшмлчлаьшюшэрерврзшпревьгжьедфшеюрваьдэсшпвсыьтсеишыьерчщшдхыпосврюлтсфшэлэшсшвлти ьшюшэлаьдеюьшвь ьтсфшрусчльедфшддщоэлштлштржегжэштлшюл ьышшсосшпжгосатщзшсосшдшчрдежпрышчофшшддщоэжшргфмлеьоитрштжутршпвсдолеишюшюсчьшдчлттрнршчрыл тьнршмлчлтсфштлшпрвелоьшлэлчьыссшэлэшюдьнчлшокгщьшэрыыьтелвссштрющьшсчьсшсшвлдджучьтсфштлшеьыжшэлеьнрвсаьдэсшпвсюьедеюжкедфшюшхерыштьгрои рышчрыл тьышмлчлтссшыщшпрпвргжьышжожа сеишыьерчш ьворэлшъроыдлшэлэшсмюьдетршюшвлддэлмьшшшшшшшюьосэсзшдщйсэшвлд сяврюлошмлнлчратщьшпсдиыьтлшэрервщьшющнофчьосшпвсыьвтршелэпроимрюлодфшртшчофшхернршелэштлмщюльыщышалдеретщышыьерчрышдыревьошэлэсьшгжэющшалйьшюдевьалкедфшюшмл сяврюлттщъшеьэделъшсшпщелодфшпрчделюсеишгжэющшюшдрреюьедеюссшдшалдеретрзшелгосбьзшшшдлылфшалделфшсшелэшчлоььюшхерышмлчлтссшыщшгжчьышвлмвлглещюлеишгроььшдрювьыьттщзшсшпврчюстжещзшюлвслтешелэрнршалдеретрнршыьерчлшюшэлаьдеюьшэрвпждрюшеьэдерюшчофшпрчдаерюшалдерешыруьеьшюмфеишаершжнрчтрштршчофшжчргдеюлшюрешюлышюрзтлшсшысвшпрвжддэсшсшпрлтносздэсшвьлосмжзеьшглмрющзшалдеретщзшыьерчшпрш ьворэжшъроыджпрчдаселзеьшалдерещшгжэюшпршэрвпждлышпжтэежлбскшсшэлпселосмлбскшырутршпврдершрпждесеишлшюрешпвргьощшожа ьшрделюсеиюрмиысеьшэлэсьтсгжчишеьдерющьшеьэдещштжутршюмфеишпршыьти ьзшыьвьшшпвьчоруьтсфшстлаьшювфчшосшдвлгрельешмл сявжзеьшсъшпрдвьчдеюрышдожалзтрзшпьвьделтрюэсшдсыюрорювлд сявжзеьшсъшелэсышалдеретщышыьерчрыювфчшосшюшвьмжоиелеьшпрожасолдишелэлфшжушървр лфшвлд сяврюэлшвлмюьшаершьдосшющшгвлосшюшэлаьдеюьшеьдерющъшчлттщъшбьощьшвлддэлмщштршсш ьворэшъроыдшгщоштьшелэшжушпврдешпрдоьшгжэющшшэрервлфшчьздеюсеьоитршющчьофьедфшалдерерзшчлои ьшртшлтлосмсврюлошжуьшэртэвьетщьшдорюлшсшпщелодфшжнлчлеишэлэсысшртсшырносшгщшгщеишфштьшмтлкшэлэшмлпврнвлыысврюлеишелэрзшстежсесютщзшлтлосмшелэшаершчлюлзеьшпврдершдчьольышдоьчжкйсзшорнсаьдэсзш лнпрчдаселзеьшалдерещшгснвлыышеьшплвшпрдоьчрюлеьоитщъшгжэюшпршэрвпждлыпврюьчсеьшеьдесврюлтсьшлтлорнсатршпштршпвсшпрырйсшгснвлыытршсшхершьйштьшюдшгснвлыыщшдэрвььшюдьнршеруьшчлоьэрштьшюдьнчлшвлгрелкешрдтрютлфшалдеишмлчлтсфшшюшерышэлэшырутршсъшжожа сеипвьчорусеьшыьерчшргжаьтсфшпьвьделтрюэсшдсыюрорюшюшхерышмлчлтссшрдтрюлттщзштлшдхыпосврюлтссштршпрпвьутьыжшвлгрелкйсзштлшрдтрюьшделесдесэсшгснвлыывьлосмжзеьшсшпвреьдесвжзеьшьнршжгьчсеьдишаершвьмжоиелещшжожа сосдивлд сявжзеьшдрргйьтсьсосшхершртсшрчстлэрющьшюерврзшюлвслтешпврдерштлшдожалзшпвргоьышдшктсэрчрыгртждшлшаершьдосшрешгснвлыышпьвьзесшэшевснвлыылышеврзэлышгжэюшсосшчлуьшгрои ьшжожа ледфшосшвьмжоиелещшэрнчлшжожа ледфшлшэрнчлштьешаергщшреюьесеиштлшхерешюрпврдшхыпсвсаьдэсшжуьшыруьешпртлчргсеидфшпрньтьвсврюлеишытрнршеьдерющъшпьвьделтрюрэшсшпрдоьчсеишмлшыьевсэлысшнолмлысшыруьешгщеишсштьшюсчтргртждшэлэсьшющшыруьеьшпвсчжылеишпвсыьтьтсфшчофшхерзшырчьосшпоф жйсьшаьорюьаэсшюьчиштьшелэшалдершюдевьалкедфшюшусмтсшърефшюдевьалкедфшсшхершдлырьшпревфдлкйььшюршюдьзшхерзшсдервссштршргшхерышфшвлддэлужшпреры\n",
            "Decrypted text:\n",
            "продвинутое машинное обучение домашнее задание третье домашнее задание посвящено достаточно простой но надеюсь интересной задаче в которой потребуется творчески применить методы сэмплирования как и раньше в качестве решения ожидается ссылка на ноутбук на вашем  или публичный или с доступом для  ссылку обязательно нужно прислать в виде сданного домашнего задания на портале академии как всегда любые комментарии новые идеи и рассуждения на тему категорически приветствуются в этом небольшом домашнем задании мы попробуем улучшить метод шерлока холмса как известно в рассказе       великий сыщик расшицровал загадочные письмена которые выглядели примерно такпользовался он для этого так называемым частотным методом смотрел какие буквы чаще встречаются в зашицрованных текстах и пытался подставить буквы в соответствии с частотной таблифей   самая частая и так далеев этом задании мы будем разрабатывать более современный и продвинутый вариант такого частотного метода в качестве корпусов текстов для подсчтов частот можете взять что угодно но для удобства вот вам война и мир порусски и поанглийски реализуйте базовый частотный метод по шерлоку холмсуподсчитайте частоты букв по корпусам пунктуафию и капитализафию можно просто опустить а вот пробелы лучше оставитьвозьмите какиенибудь тестовые тексты нужно взять по меньшей мере  предложения иначе вряд ли сработает зашицруйте их посредством случайной перестановки символоврасшицруйте их таким частотным методомвряд ли в результате получилась такая уж хорошая расшицровка разве что если вы брали в качестве тестовых данных фелые рассказы но и шерлок холмс был не так уж прост после буквы  которая действительно выделяется частотой дальше он анализировал уже конкретные слова и пытался угадать какими они могли бы быть я не знаю как запрограммировать такой интуитивный анализ так что давайте просто сделаем следующий логический шагподсчитайте частоты биграмм те пар последовательных букв по корпусампроведите тестирование аналогично п но при помощи биграммно и это ещ не вс биграммы скорее всего тоже далеко не всегда работают основная часть задания  в том как можно их улучшитьпредложите метод обучения перестановки символов в этом задании основанный на сэмплировании но попрежнему работающий на основе статистики биграммреализуйте и протестируйте его убедитесь что результаты улучшилисьрасшицруйте сообщениеили это они одинаковые второй вариант просто на случай проблем с юникодомбонус а что если от биграмм перейти к триграммам тройкам букв или даже больше улучшатся ли результаты когда улучшатся а когда нет чтобы ответить на этот вопрос эмпирически уже может понадобиться погенерировать много тестовых перестановок и последить за метриками глазами может быть и не виднобонус какие вы можете придумать применения для этой модели пляшущие человечки ведь не так часто встречаются в жизни хотя встречаются и это самое потрясающее во всей этой истории но об этом я расскажу потом\n",
            "Accuracy: 99.66\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fb5plL-U5Lxn"
      },
      "source": [
        "# Расшифруйте сообщение:\n",
        "დჳჵჂႨშႼႨშჂხჂჲდႨსႹႭჾႣჵისႼჰႨჂჵჂႨႲႹႧჲჂႨსႹႭჾႣჵისႼჰႨჲდႩჳჲႨჇႨႠჲႹქႹႨჳႹႹჱჶდსჂႽႨႩႹჲႹႭႼჰႨჵდქႩႹႨႲႭႹႧჂჲႣჲიႨჳႩႹႭდდႨშჳდქႹႨშႼႨშჳდႨჳხდჵႣჵჂႨႲႭႣშჂჵისႹႨჂႨႲႹჵჇႧჂჲდႨჾႣႩჳჂჾႣჵისႼჰႨჱႣჵჵႨეႣႨႲႹჳჵდხსდდႨႧდჲშდႭჲႹდႨეႣხႣსჂდႨႩჇႭჳႣႨႾႹჲႽႨႩႹსდႧსႹႨႽႨსჂႧდქႹႨსდႨႹჱდჶႣნ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WM_eKl9q5LHV",
        "outputId": "615f74e9-28d9-4550-a4fc-13dfb53691fe"
      },
      "source": [
        "from tqdm import tqdm \n",
        "\n",
        "mc_text = 'დჳჵჂႨშႼႨშჂხჂჲდႨსႹႭჾႣჵისႼჰႨჂჵჂႨႲႹႧჲჂႨსႹႭჾႣჵისႼჰႨჲდႩჳჲႨჇႨႠჲႹქႹႨჳႹႹჱჶდსჂႽႨႩႹჲႹႭႼჰႨჵდქႩႹႨႲႭႹႧჂჲႣჲიႨჳႩႹႭდდႨშჳდქႹႨშႼႨშჳდႨჳხდჵႣჵჂႨႲႭႣშჂჵისႹႨჂႨႲႹჵჇႧჂჲდႨჾႣႩჳჂჾႣჵისႼჰႨჱႣჵჵႨეႣႨႲႹჳჵდხსდდႨႧდჲშდႭჲႹდႨეႣხႣსჂდႨႩჇႭჳႣႨႾႹჲႽႨႩႹსდႧსႹႨႽႨსჂႧდქႹႨსდႨႹჱდჶႣნ'\n",
        "decryptions = list()\n",
        "\n",
        "decryptor = Decryptor(corp_ru, mc_text, iterations=25000)\n",
        "\n",
        "for _ in tqdm(range(50), position=0, leave=True):\n",
        "  decryptions.append(decryptor.ngram_mcmc(2))\n",
        "decryptions = sorted(decryptions, key = lambda x: x[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 50/50 [19:18<00:00, 23.17s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQFFZ2pAOmEH",
        "outputId": "366bcabe-2286-4300-a356-9e3077b805ac"
      },
      "source": [
        "decryptions[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(-1808.3747244571043,\n",
              "  'если вы вимите норзальный или подти норзальный текст у этого соочшения который легко продитать скорее всего вы все смелали правильно и полудите заксизальный чалл ба послемнее детвертое бамание курса хотя конедно я нидего не очешаж'),\n",
              " (-1808.2435630263944,\n",
              "  'если вы вимите нордальный или почти нордальный текст у этого сообщения который легко прочитать скорее всего вы все смелали правильно и получите даксидальный балл за послемнее четвертое замание курса хотя конечно я ничего не обещаж'),\n",
              " (-1808.197597035729,\n",
              "  'если вы вимите норжальный или подти норжальный текст у этого соочшения который легко продитать скорее всего вы все смелали правильно и полудите жаксижальный чалл за послемнее детвертое замание курса ботя конедно я нидего не очешаф'),\n",
              " (-1807.9434386493742,\n",
              "  'если вы вимите норзальный или подти норзальный текст у этого соочшения который легко продитать скорее всего вы все смелали правильно и полудите заксизальный чалл ба послемнее детвертое бамание курса хотя конедно я нидего не очешаю'),\n",
              " (-1807.884744913156,\n",
              "  'если вы вимите норжальный или подти норжальный текст у чтого сообщения который легко продитать скорее всего вы все смелали правильно и полудите жаксижальный балл за послемнее детвертое замание курса хотя конедно я нидего не обещаю'),\n",
              " (-1807.718359064704,\n",
              "  'если вы вимите норжальный или подти норжальный текст у этого сообчения который легко продитать скорее всего вы все смелали правильно и полудите жаксижальный балл за послемнее детвертое замание курса хотя конедно я нидего не обечаю'),\n",
              " (-1807.5474067249108,\n",
              "  'если вы вимите норзальный или подти норзальный текст у этого сообжения который легко продитать скорее всего вы все смелали правильно и полудите заксизальный балл ча послемнее детвертое чамание курса хотя конедно я нидего не обежаю'),\n",
              " (-1807.0681173367539,\n",
              "  'если вы вимите норзальный или подти норзальный текст у этого соошжения который легко продитать скорее всего вы все смелали правильно и полудите заксизальный шалл ча послемнее детвертое чамание курса ботя конедно я нидего не ошежах'),\n",
              " (-1806.4504473889133,\n",
              "  'если вы вимите норшальный или подти норшальный текст у чтого сообщения который легко продитать скорее всего вы все смелали правильно и полудите шаксишальный балл за послемнее детвертое замание курса хотя конедно я нидего не обещаю'),\n",
              " (-1806.1556134610726,\n",
              "  'если вы вимите норчальный или подти норчальный текст у этого соожбения который легко продитать скорее всего вы все смелали правильно и полудите чаксичальный жалл за послемнее детвертое замание курса хотя конедно я нидего не ожебаф')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2gpaxbxr_7i"
      },
      "source": [
        "# А что если от биграмм перейти к триграммам (тройкам букв) или даже больше? Улучшатся ли результаты? Когда улучшатся, а когда нет?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SC4iZMX3SRR"
      },
      "source": [
        "В качестве оценки результатов возьмем вероятно корректный закодированный текст и будем считать среднюю долю правильно декодированных алгоритмом букв."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "kIZSxwAcIewI",
        "outputId": "ee1f4669-cf7d-4dee-a993-4d35eec7f27a"
      },
      "source": [
        "true_text = 'если вы видите нормальный или почти нормальный текст у этого сообщения который легко прочитать скорее всего вы все сделали правильно и получите максимальный балл за последнее четвертое задание курса хотя конечно я ничего не обещаю'\n",
        "true_text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'если вы видите нормальный или почти нормальный текст у этого сообщения который легко прочитать скорее всего вы все сделали правильно и получите максимальный балл за последнее четвертое задание курса хотя конечно я ничего не обещаю'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOJlgGS5K683",
        "outputId": "0c4f022c-e672-4759-e8c0-ac4f3bec3b04"
      },
      "source": [
        "decryptor = Decryptor(corp_ru, mc_text, iterations=25000)\n",
        "decryptions_1 = list()\n",
        "\n",
        "for n in tqdm(range(2,8), position=0, leave=True):\n",
        "  for _ in range(50):\n",
        "    _, decrypted_text = decryptor.ngram_mcmc(n)\n",
        "    decryptions_1.append((n, decrypted_text, get_pred_score(true_text, decrypted_text)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 6/6 [1:50:01<00:00, 1100.33s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahl8ktEOp0mr",
        "outputId": "5e6884bc-e1a2-4cfa-8f46-0ee019848eb5"
      },
      "source": [
        "for i in range(6):\n",
        "  best_acc = 0\n",
        "  mean_acc = 0\n",
        "  for var in decryptions_1[i*50:(i+1)*50]:\n",
        "    mean_acc+=var[2]\n",
        "    if var[2]>best_acc:\n",
        "      best_acc = var[2]\n",
        "      text = var[1]\n",
        "  print(f'For {var[0]}-grams:', f'Best accuracy: {best_acc}%', f'Mean accuracy: {round(mean_acc/50, 2)}%', f'Best decryption:\\n{text}\\n', sep = '\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For 2-grams:\n",
            "Best accuracy: 95.22%\n",
            "Mean accuracy: 73.16%\n",
            "Best decryption:\n",
            "если вы вичите нормальный или подти нормальный текст у этого сообщения который легко продитать скорее всего вы все счелали правильно и полудите максимальный балл за послечнее детвертое зачание курса хотя конедно я нидего не обещаж\n",
            "\n",
            "For 3-grams:\n",
            "Best accuracy: 100.0%\n",
            "Mean accuracy: 80.54%\n",
            "Best decryption:\n",
            "если вы видите нормальный или почти нормальный текст у этого сообщения который легко прочитать скорее всего вы все сделали правильно и получите максимальный балл за последнее четвертое задание курса хотя конечно я ничего не обещаю\n",
            "\n",
            "For 4-grams:\n",
            "Best accuracy: 100.0%\n",
            "Mean accuracy: 67.25%\n",
            "Best decryption:\n",
            "если вы видите нормальный или почти нормальный текст у этого сообщения который легко прочитать скорее всего вы все сделали правильно и получите максимальный балл за последнее четвертое задание курса хотя конечно я ничего не обещаю\n",
            "\n",
            "For 5-grams:\n",
            "Best accuracy: 98.26%\n",
            "Mean accuracy: 25.66%\n",
            "Best decryption:\n",
            "если вы видите нормальный или почти нормальный текст у этого сооъщения который легко прочитать скорее всего вы все сделали правильно и получите максимальный ъалл за последнее четвертое задание курса хотя конечно я ничего не оъещац\n",
            "\n",
            "For 6-grams:\n",
            "Best accuracy: 16.09%\n",
            "Mean accuracy: 2.84%\n",
            "Best decryption:\n",
            "гыъвщяьщяв вбгщлорчфъюльещвъвщуошбвщлорчфъюльещбгкыбщнщмбоэощыооийглвзщкоборьещъгэкощурошвбфбющыкорггщяыгэощяьщяыгщы гъфъвщурфявъюлощвщуоъншвбгщчфкывчфъюльещифъъщдфщуоыъг лггщшгбягрбогщдф флвгщкнрыфщсобзщколгшлощзщлвшгэощлгщоигйфх\n",
            "\n",
            "For 7-grams:\n",
            "Best accuracy: 20.43%\n",
            "Mean accuracy: 3.87%\n",
            "Best decryption:\n",
            "ръфз ый ызчзэр гбкхафжгйщ зфз вблэз гбкхафжгйщ эрмъэ д цэбяб ъббосргзш мбэбкйщ фрямб вкблзэаэж ъмбкрр ыъряб ый ыър ъчрфафз вкаызфжгб з вбфдлзэр хамъзхафжгйщ оафф иа вбъфрчгрр лрэыркэбр иачагзр мдкъа убэш мбгрлгб ш гзлряб гр борсаь\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMA97siLzIut"
      },
      "source": [
        "Относительно метрики mean accuracy лучшим подходом явлеется использование триграмм. Пятиграммы и более являются неэффектиными в данной задаче из-за малой доли закодированных (5+)грамм в тренировочном корпусе"
      ]
    }
  ]
}